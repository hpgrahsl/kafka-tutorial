= Developing Consumers and Producers in Java
include::_attributes.adoc[]

In this example, we are going to develop two simple services which will produce data to and consume data from a Kafka topic named `songs`.

TIP: By default, it is not necessary to create the Kafka topic manually, Kafka creates it automatically with default parameters.

The first service acts as a Kafka producer to write song related information (e.g. _id_, _author_, _name_) into the `songs` topic. Then there is a second service acting as a Kafka consumer which reads this data from the `songs` topic. Usually this consumer would perform some "real business logic" such as taking the songs data and process it somehow, e.g. adding songs in a graph database like Neo4J, or build a fulltext search index based on Elastic. However, for the sake of simplicity, our service is just printing the consumed data to the console and exposes every consumed Kafka record over a server-sent event (SSE) stream for connected HTTP clients.

include::partial$kafka-up-dc.adoc[]

It's best to have 4 terminal windows open for running this example, 2 terminals for the producer and consumer services, and another 2 terminals for sending and receiving HTTP requests/responses.

image::terminals-song.png[]

[#producer-java]
== Producing messages with Java

The producer code is at {github-repo}/{apps-folder}/song-app[Song App, window=_blank].

[#deploying-producer]
=== Deploying Producer

In this case, the Spring Boot service is deployed to produce songs.
You've got two options, using Docker or building the service yourself from the sources.
In terminal 1, run one of these two options:

[tabs]
====
Building & Run::
+
--
[.console-input]
[source, bash-shell,subs="+macros,+attributes"]
----
cd $TUTORIAL_HOME/apps/song-app/springboot/song-app
./mvnw clean package -DskipTests
----

[.console-input]
[source, bash-shell,subs="+macros,+attributes"]
----
docker build -t quay.io/rhdevelopers/kafka-tutorial-song-app-springboot:latest .
----

[.console-input]
[source, bash-shell,subs="+macros,+attributes"]
----
docker run --rm --network=kafka-tutorial -p 8080:8080 quay.io/rhdevelopers/kafka-tutorial-song-app-springboot:latest
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
2022-12-19T12:31:01.985Z  INFO 1 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2022-12-19T12:31:01.986Z  INFO 1 --- [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 646 ms
2022-12-19T12:31:02.334Z  INFO 1 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2022-12-19T12:31:02.349Z  INFO 1 --- [           main] org.acme.song.app.SongApplication        : Started SongApplication in 1.382 seconds (process running for 1.821)
----
--
Docker::
+
--
[.console-input]
[source, bash-shell,subs="+macros,+attributes"]
----
docker run --rm --network=kafka-tutorial -p 8080:8080 quay.io/rhdevelopers/kafka-tutorial-song-app-springboot:v22.12
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
2022-12-19T12:31:01.985Z  INFO 1 --- [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2022-12-19T12:31:01.986Z  INFO 1 --- [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 646 ms
2022-12-19T12:31:02.334Z  INFO 1 --- [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2022-12-19T12:31:02.349Z  INFO 1 --- [           main] org.acme.song.app.SongApplication        : Started SongApplication in 1.382 seconds (process running for 1.821)
----
--
====

[#consumer-java]
== Consuming messages with Java

The consumer code is at {github-repo}/{apps-folder}/song-indexer-app[Song Indexer App, window=_blank].

[#deploying-consumer]
=== Deploying Consumer

In this case, the Spring Boot service is deployed to consume songs.
You've got two options, using Docker or building the service yourself from the sources.
In terminal 2, run one of these two options:

[tabs]
====
Build & Run::
+
--
[.console-input]
[source, bash-shell,subs="+macros,+attributes"]
----
cd $TUTORIAL_HOME/apps/song-indexer-app/springboot/song-indexer-app
./mvnw clean package -DskipTests
----

[.console-input]
[source, bash-shell,subs="+macros,+attributes"]
----
docker build -t quay.io/rhdevelopers/kafka-tutorial-song-indexer-app-springboot:latest .
----

[.console-input]
[source, bash-shell,subs="+macros,+attributes"]
----
docker run --rm --network=kafka-tutorial -p 9090:8080 quay.io/rhdevelopers/kafka-tutorial-song-indexer-app-springboot:latest
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
2022-12-15T09:35:14.545+01:00  INFO 43531 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] (Re-)joining group
2022-12-15T09:35:14.549+01:00  INFO 43531 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] Successfully joined group with generation Generation{generationId=35, memberId='consumer-G1-1-678970e3-7deb-4679-a469-10b1b53a200c', protocol='range'}
2022-12-15T09:35:14.550+01:00  INFO 43531 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] Finished assignment for group at generation 35: {consumer-G1-1-678970e3-7deb-4679-a469-10b1b53a200c=Assignment(partitions=[songs-0])}
2022-12-15T09:35:14.555+01:00  INFO 43531 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] Successfully synced group in generation Generation{generationId=35, memberId='consumer-G1-1-678970e3-7deb-4679-a469-10b1b53a200c', protocol='range'}
2022-12-15T09:35:14.555+01:00  INFO 43531 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] Notifying assignor about the new Assignment(partitions=[songs-0])
2022-12-15T09:35:14.557+01:00  INFO 43531 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] Adding newly assigned partitions: songs-0
2022-12-15T09:35:14.564+01:00  INFO 43531 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] Setting offset for partition songs-0 to the committed offset FetchPosition{offset=49, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 0 rack: null)], epoch=0}}
2022-12-15T09:35:14.565+01:00  INFO 43531 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : G1: partitions assigned: [songs-0]
----
--
Docker::
+
--
[.console-input]
[source, bash-shell,subs="+macros,+attributes"]
----
docker run --rm --network=kafka-tutorial -p 9090:8080 quay.io/rhdevelopers/kafka-tutorial-song-indexer-app-springboot:v22.12
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
2022-12-15T09:44:02.594+01:00  INFO 45680 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] Finished assignment for group at generation 1: {consumer-G1-1-95c3358a-e4a1-4d93-bd10-37453f8d21ed=Assignment(partitions=[songs-0])}
2022-12-15T09:44:02.632+01:00  INFO 45680 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] Successfully synced group in generation Generation{generationId=1, memberId='consumer-G1-1-95c3358a-e4a1-4d93-bd10-37453f8d21ed', protocol='range'}
2022-12-15T09:44:02.633+01:00  INFO 45680 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] Notifying assignor about the new Assignment(partitions=[songs-0])
2022-12-15T09:44:02.637+01:00  INFO 45680 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] Adding newly assigned partitions: songs-0
2022-12-15T09:44:02.646+01:00  INFO 45680 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] Found no committed offset for partition songs-0
2022-12-15T09:44:02.651+01:00  INFO 45680 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-G1-1, groupId=G1] Found no committed offset for partition songs-0
2022-12-15T09:44:02.660+01:00  INFO 45680 --- [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-G1-1, groupId=G1] Resetting offset for partition songs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 0 rack: null)], epoch=0}}.
2022-12-15T09:44:02.682+01:00  INFO 45680 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : G1: partitions assigned: [songs-0]
----
--
====

[#providing-song]
=== Providing Songs

The song indexer service consume songs that have been produced to the `songs` topic. Besides printing the song to the console it exposes every consumed record as sever-sent event (SSE) over HTTP.
In the terminal 3, run the following command to start listening for sever-sent events over the HTTP connection:

[.console-input]
[source, bash-shell,subs="+macros,+attributes"]
----
http GET localhost:9090/events --stream --timeout=600
----

The song service can produce songs into the `songs` the topic. For that, it exposes an HTTP POST endpoint which allows us to publish songs.
In the terminal 4, run the following command to publish a song:

[.console-input]
[source, bash-shell,subs="+macros,+attributes"]
----
http POST localhost:8080/songs id=1000 name='Portals' author='Alan Silvestri'
----

[.console-ouput]
[source, bash-shell,subs="+macros,+attributes"]
----
HTTP/1.1 201
Connection: keep-alive
Content-Length: 0
Date: Thu, 15 Dec 2022 08:46:57 GMT
Keep-Alive: timeout=60
----

To verify that the song has been processed, check terminal 2 (`song indexer service`) for the last couple of log lines:

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
2022-12-15T09:47:08.234+01:00  INFO 45680 --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : G1: partitions assigned: [songs-0]
Song[id=1000, name=Portals, author=Alan Silvestri, op=ADD] indexed.
2022-12-15T09:49:09.068+01:00  INFO 46855 --- [ntainer#0-0-C-1] reactor.Flux.SinkManyBestEffort.1        : onNext(ServerSentEvent [id = '6fad2b6f-6400-45a1-9dc9-8bcfed7b5399', event='null', retry=null, comment='null', data=Song 1000 processed])
----

And in the terminal 4, you should see that the sever-sent event has been streamed successfully:

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
HTTP/1.1 200 OK
Content-Type: text/event-stream;charset=UTF-8
Vary: Origin
Vary: Access-Control-Request-Method
Vary: Access-Control-Request-Headers
transfer-encoding: chunked

id:6fad2b6f-6400-45a1-9dc9-8bcfed7b5399
data:Song 1000 processed
----

[#java-cleanup]
== Clean Up

Stop the processes that are running in the terminal 1 and 2 by typing kbd:[Ctrl + C].

include::partial$kafka-restart.adoc[]